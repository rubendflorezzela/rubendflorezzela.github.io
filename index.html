<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ruben Dario Florez-Zela Â· Computational Neuroengineering Researcher</title>
<link href="https://fonts.googleapis.com/css2?family=DM+Serif+Display:ital@0;1&family=DM+Sans:opsz,wght@9..40,300;9..40,400;9..40,500;9..40,600&family=DM+Mono:wght@400;500&display=swap" rel="stylesheet">

<!-- Google tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-XXXXXXXX');
</script>

<style>
  :root {
    --navy:        #0a1628;
    --navy-mid:    #122040;
    --accent:      #2563eb;
    --accent-light:#3b82f6;
    --teal:        #0d9488;
    --teal-light:  #14b8a6;
    --light:       #f0f4ff;
    --muted:       #64748b;
    --border:      #e2e8f0;
    --white:       #ffffff;
    --success:     #34d399;
  }

  * { margin:0; padding:0; box-sizing:border-box; }

  html { scroll-behavior: smooth; }

  body {
    font-family: 'DM Sans', sans-serif;
    background: var(--white);
    color: var(--navy);
    line-height: 1.7;
  }

  /* â”€â”€ NAV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  nav {
    position: sticky;
    top: 0;
    z-index: 200;
    background: rgba(255,255,255,0.97);
    backdrop-filter: blur(12px);
    border-bottom: 1px solid var(--border);
    padding: 0 2rem;
    display: flex;
    align-items: center;
    justify-content: space-between;
    height: 56px;
    gap: 1rem;
  }
  .nav-name {
    font-family: 'DM Mono', monospace;
    font-size: 0.8rem;
    font-weight: 500;
    color: var(--accent);
    letter-spacing: 0.05em;
    text-transform: uppercase;
    white-space: nowrap;
    flex-shrink: 0;
  }
  .nav-center {
    display: flex;
    gap: 2rem;
    list-style: none;
  }
  .nav-center a {
    font-size: 0.82rem;
    font-weight: 500;
    color: var(--muted);
    text-decoration: none;
    letter-spacing: 0.02em;
    transition: color 0.2s;
  }
  .nav-center a:hover { color: var(--accent); }

  .nav-right {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    flex-shrink: 0;
  }

  /* Language Toggle */
  .lang-toggle {
    display: flex;
    align-items: center;
    background: var(--light);
    border: 1px solid var(--border);
    border-radius: 20px;
    padding: 2px;
    gap: 2px;
  }
  .lang-btn {
    font-family: 'DM Mono', monospace;
    font-size: 0.72rem;
    font-weight: 500;
    padding: 0.25rem 0.65rem;
    border-radius: 16px;
    border: none;
    cursor: pointer;
    transition: background 0.2s, color 0.2s;
    background: transparent;
    color: var(--muted);
    letter-spacing: 0.05em;
  }
  .lang-btn.active {
    background: var(--accent);
    color: white;
  }

  /* CV Download button in nav */
  .btn-cv-nav {
    display: flex;
    align-items: center;
    gap: 0.4rem;
    background: var(--navy);
    color: white;
    padding: 0.38rem 0.9rem;
    border-radius: 4px;
    text-decoration: none;
    font-size: 0.78rem;
    font-weight: 500;
    transition: background 0.2s, transform 0.15s;
    white-space: nowrap;
  }
  .btn-cv-nav:hover { background: var(--accent); transform: translateY(-1px); }
  .btn-cv-nav svg { width:13px; height:13px; }

  /* â”€â”€ HERO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .hero {
    background: var(--navy);
    color: white;
    padding: 5rem 2rem;
    position: relative;
    overflow: hidden;
  }
  .hero::before {
    content: '';
    position: absolute;
    top: -60px; right: -60px;
    width: 520px; height: 520px;
    background: radial-gradient(circle, rgba(37,99,235,0.28) 0%, transparent 70%);
    pointer-events: none;
  }
  .hero::after {
    content: '';
    position: absolute;
    bottom: -80px; left: 10%;
    width: 420px; height: 420px;
    background: radial-gradient(circle, rgba(13,148,136,0.18) 0%, transparent 70%);
    pointer-events: none;
  }
  .hero-grid {
    position: absolute;
    inset: 0;
    background-image:
      linear-gradient(rgba(255,255,255,0.025) 1px, transparent 1px),
      linear-gradient(90deg, rgba(255,255,255,0.025) 1px, transparent 1px);
    background-size: 40px 40px;
    pointer-events: none;
  }
  .hero-inner {
    max-width: 1100px;
    margin: 0 auto;
    position: relative;
    z-index: 1;
    display: flex;
    align-items: center;
    gap: 3rem;
    flex-wrap: wrap;
  }
  
  /* Foto circular profesional - VersiÃ³n elegante */
  .profile-container {
    flex-shrink: 0;
    position: relative;
  }
  .profile-ring {
    width: 160px;
    height: 160px;
    border-radius: 50%;
    background: linear-gradient(135deg, var(--accent), var(--teal));
    padding: 3px;
    box-shadow: 0 15px 30px -8px rgba(0,0,0,0.3);
  }
  .profile-img {
    width: 100%;
    height: 100%;
    border-radius: 50%;
    object-fit: cover;
    border: 3px solid white;
  }
  
  .hero-content {
    flex: 1;
    min-width: 300px;
  }
  
  .hero-tag {
    display: inline-block;
    font-family: 'DM Mono', monospace;
    font-size: 0.72rem;
    font-weight: 500;
    color: var(--accent-light);
    letter-spacing: 0.12em;
    text-transform: uppercase;
    margin-bottom: 1rem;
    border: 1px solid rgba(59,130,246,0.4);
    padding: 0.3rem 0.8rem;
    border-radius: 2px;
  }
  .hero h1 {
    font-family: 'DM Serif Display', serif;
    font-size: clamp(2.2rem, 4vw, 3.2rem);
    line-height: 1.1;
    margin-bottom: 0.5rem;
    letter-spacing: -0.01em;
  }
  .hero h1 span { 
    color: var(--accent-light); 
    font-style: italic; 
  }
  .hero-subtitle {
    font-size: 1rem;
    color: rgba(255,255,255,0.7);
    margin: 1rem 0 1.5rem;
    font-weight: 300;
    max-width: 600px;
  }
  
  .hero-metrics {
    display: flex;
    gap: 2rem;
    margin-bottom: 2rem;
    flex-wrap: wrap;
  }
  .metric-num {
    font-family: 'DM Serif Display', serif;
    font-size: 1.8rem;
    color: white;
    line-height: 1;
  }
  .metric-label {
    font-size: 0.7rem;
    color: rgba(255,255,255,0.4);
    text-transform: uppercase;
    letter-spacing: 0.08em;
    margin-top: 0.2rem;
  }
  
  .hero-links {
    display: flex;
    gap: 0.85rem;
    flex-wrap: wrap;
    align-items: center;
  }
  .btn-primary {
    background: var(--accent);
    color: white;
    padding: 0.6rem 1.3rem;
    border-radius: 4px;
    text-decoration: none;
    font-size: 0.85rem;
    font-weight: 500;
    transition: all 0.2s;
  }
  .btn-primary:hover { background: #1d4ed8; transform: translateY(-2px); }

  .btn-outline {
    border: 1px solid rgba(255,255,255,0.22);
    color: rgba(255,255,255,0.75);
    padding: 0.6rem 1.3rem;
    border-radius: 4px;
    text-decoration: none;
    font-size: 0.85rem;
    font-weight: 400;
    transition: all 0.2s;
  }
  .btn-outline:hover { border-color: white; color: white; transform: translateY(-2px); }

  .btn-cv-hero {
    display: inline-flex;
    align-items: center;
    gap: 0.45rem;
    background: var(--teal);
    color: white;
    padding: 0.6rem 1.3rem;
    border-radius: 4px;
    text-decoration: none;
    font-size: 0.85rem;
    font-weight: 500;
    transition: all 0.2s;
  }
  .btn-cv-hero:hover { background: var(--teal-light); transform: translateY(-2px); }
  .btn-cv-hero svg { width: 15px; height: 15px; }

  /* â”€â”€ SECTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  section {
    padding: 5rem 2rem;
    border-bottom: 1px solid var(--border);
  }
  section:nth-child(even) { background: #fafbff; }
  .section-inner { max-width: 1100px; margin: 0 auto; }
  .section-label {
    font-family: 'DM Mono', monospace;
    font-size: 0.7rem;
    font-weight: 500;
    color: var(--teal);
    letter-spacing: 0.12em;
    text-transform: uppercase;
    margin-bottom: 0.7rem;
  }
  .section-title {
    font-family: 'DM Serif Display', serif;
    font-size: 2rem;
    color: var(--navy);
    margin-bottom: 2.5rem;
    line-height: 1.2;
  }

  /* â”€â”€ ABOUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .about-text p {
    font-size: 1.05rem;
    color: #334155;
    margin-bottom: 1.2rem;
    max-width: 700px;
  }
  .about-badges {
    display: flex;
    gap: 0.6rem;
    flex-wrap: wrap;
    margin-top: 1.8rem;
  }
  .badge {
    font-size: 0.75rem;
    font-weight: 500;
    padding: 0.35rem 0.85rem;
    border-radius: 20px;
    background: var(--light);
    color: var(--accent);
    border: 1px solid #dbeafe;
  }

  /* â”€â”€ VISION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .vision-block {
    display: grid;
    grid-template-columns: 1fr auto;
    gap: 3rem;
    align-items: center;
  }
  .vision-quote { 
    border-left: 3px solid var(--accent); 
    padding-left: 1.5rem; 
  }
  .vision-quote p { 
    font-size: 1.05rem; 
    color: #334155; 
    line-height: 1.8; 
    font-style: italic; 
  }
  .vision-pillars { 
    display: flex; 
    flex-direction: column; 
    gap: 0.85rem; 
    min-width: 200px; 
  }
  .pillar {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    padding: 0.6rem 1rem;
    background: var(--light);
    border: 1px solid #dbeafe;
    border-radius: 6px;
    transition: transform 0.2s, box-shadow 0.2s;
  }
  .pillar:hover { 
    transform: translateX(4px); 
    box-shadow: 0 2px 12px rgba(37,99,235,0.1); 
  }
  .pillar-icon { font-size: 1.1rem; }
  .pillar-label { font-size: 0.8rem; font-weight: 600; color: var(--navy); }

  /* â”€â”€ INTERESTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .interests-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
    gap: 1.2rem;
  }
  .interest-card {
    padding: 1.5rem;
    border: 1px solid var(--border);
    border-radius: 6px;
    background: white;
    border-left: 3px solid var(--accent);
    transition: box-shadow 0.2s, transform 0.2s;
  }
  .interest-card:hover { 
    box-shadow: 0 6px 24px rgba(0,0,0,0.08); 
    transform: translateY(-2px); 
  }
  .interest-card h4 { 
    font-size: 0.9rem; 
    font-weight: 600; 
    margin-bottom: 0.5rem; 
    color: var(--navy); 
  }
  .interest-card p { 
    font-size: 0.82rem; 
    color: var(--muted); 
    line-height: 1.6; 
  }

  /* â”€â”€ RESEARCH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .research-box {
    background: var(--navy);
    color: white;
    border-radius: 8px;
    padding: 2.5rem;
    position: relative;
    overflow: hidden;
  }
  .research-box::after {
    content: '';
    position: absolute;
    top: -40px; right: -40px;
    width: 300px; height: 300px;
    background: radial-gradient(circle, rgba(37,99,235,0.2) 0%, transparent 70%);
    pointer-events: none;
  }
  .research-box h3 {
    font-family: 'DM Serif Display', serif;
    font-size: 1.5rem;
    margin-bottom: 1rem;
    line-height: 1.3;
    position: relative;
    z-index: 1;
  }
  .research-box p {
    color: rgba(255,255,255,0.72);
    font-size: 0.95rem;
    margin-bottom: 1.2rem;
    max-width: 680px;
    position: relative;
    z-index: 1;
  }
  .signal-tags {
    display: flex;
    gap: 0.6rem;
    flex-wrap: wrap;
    margin-top: 1.5rem;
    position: relative;
    z-index: 1;
  }
  .signal-tag {
    font-family: 'DM Mono', monospace;
    font-size: 0.72rem;
    padding: 0.3rem 0.75rem;
    border: 1px solid rgba(59,130,246,0.45);
    color: var(--accent-light);
    border-radius: 3px;
    transition: background 0.2s;
  }
  .signal-tag:hover { background: rgba(59,130,246,0.1); }
  .status-pill {
    display: inline-flex;
    align-items: center;
    gap: 0.4rem;
    font-size: 0.72rem;
    color: var(--success);
    font-family: 'DM Mono', monospace;
    margin-bottom: 1rem;
    position: relative;
    z-index: 1;
  }
  .status-dot {
    width: 6px; height: 6px;
    background: var(--success);
    border-radius: 50%;
    animation: pulse 2s infinite;
  }
  @keyframes pulse { 0%,100%{opacity:1} 50%{opacity:0.35} }

  /* â”€â”€ DEMOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .demos-section {
    background: linear-gradient(135deg, #f8faff 0%, white 100%);
  }
  .demos-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 2rem;
  }
  .demo-card {
    background: white;
    border-radius: 16px;
    overflow: hidden;
    border: 1px solid var(--border);
    transition: all 0.3s ease;
    box-shadow: 0 4px 6px -2px rgba(0,0,0,0.05);
  }
  .demo-card:hover {
    transform: translateY(-4px);
    box-shadow: 0 20px 25px -8px rgba(37,99,235,0.15);
    border-color: var(--accent);
  }
  .demo-gif-container {
    aspect-ratio: 16/9;
    background: #000;
    border-bottom: 1px solid var(--border);
  }
  .demo-gif-container img {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }
  .demo-content {
    padding: 1.5rem;
  }
  .demo-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 0.8rem;
  }
  .demo-header h4 {
    font-size: 1rem;
    color: var(--navy);
    font-weight: 600;
  }
  .citation-pill {
    background: var(--light);
    color: var(--accent);
    padding: 0.2rem 0.8rem;
    border-radius: 30px;
    font-size: 0.7rem;
    font-weight: 600;
    font-family: 'DM Mono', monospace;
  }
  .demo-content p {
    font-size: 0.85rem;
    color: var(--muted);
    margin-bottom: 1rem;
    line-height: 1.6;
  }
  .demo-tags {
    display: flex;
    gap: 0.5rem;
    flex-wrap: wrap;
  }
  .demo-tag {
    background: var(--light);
    color: var(--accent);
    padding: 0.2rem 0.8rem;
    border-radius: 30px;
    font-size: 0.7rem;
    font-weight: 500;
    border: 1px solid #dbeafe;
  }
  .paper-divider {
    grid-column: 1 / -1;
    margin: 1rem 0;
  }
  .paper-divider h3 {
    font-size: 1.2rem;
    color: var(--navy);
    font-weight: 500;
  }
  .paper-divider h3 span {
    color: var(--accent);
    font-weight: 600;
    margin-left: 0.5rem;
    font-size: 1rem;
  }

  /* â”€â”€ PUBLICATIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .pub-list { display: flex; flex-direction: column; gap: 1.1rem; }
  .pub-card {
    padding: 1.4rem 1.5rem;
    border: 1px solid var(--border);
    border-radius: 6px;
    background: white;
    display: grid;
    grid-template-columns: 1fr auto;
    gap: 1rem;
    align-items: start;
    transition: box-shadow 0.2s, border-color 0.2s;
  }
  .pub-card:hover { 
    box-shadow: 0 4px 20px rgba(0,0,0,0.07); 
    border-color: #c7d7f8; 
  }
  .pub-card.hidden { display: none; }
  .pub-title { 
    font-size: 0.92rem; 
    font-weight: 600; 
    color: var(--navy); 
    margin-bottom: 0.4rem; 
    line-height: 1.45; 
  }
  .pub-title a { color: inherit; text-decoration: none; }
  .pub-title a:hover { color: var(--accent); }
  .pub-meta { font-size: 0.78rem; color: var(--muted); line-height: 1.6; }
  .citation-badge {
    background: #eff6ff;
    color: var(--accent);
    font-size: 0.75rem;
    font-weight: 600;
    padding: 0.25rem 0.7rem;
    border-radius: 20px;
    white-space: nowrap;
    align-self: start;
    font-family: 'DM Mono', monospace;
  }
  .pub-filters { 
    display: flex; 
    gap: 0.5rem; 
    margin-bottom: 1.5rem; 
    flex-wrap: wrap; 
  }
  .pub-filter {
    font-family: 'DM Mono', monospace;
    font-size: 0.72rem;
    font-weight: 500;
    padding: 0.35rem 0.9rem;
    border-radius: 20px;
    border: 1px solid var(--border);
    background: white;
    color: var(--muted);
    cursor: pointer;
    transition: all 0.2s;
    letter-spacing: 0.03em;
  }
  .pub-filter:hover { border-color: var(--accent); color: var(--accent); }
  .pub-filter.active { background: var(--accent); color: white; border-color: var(--accent); }
  .pub-footer {
    margin-top: 1.5rem; 
    font-size: 0.82rem; 
    color: var(--muted);
  }
  .pub-footer a { color: var(--accent); text-decoration: none; }
  .pub-footer a:hover { text-decoration: underline; }

  /* â”€â”€ TEACHING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .teaching-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 1rem;
  }
  .course-card {
    padding: 1.2rem 1.4rem;
    border: 1px solid var(--border);
    border-radius: 6px;
    background: white;
    transition: box-shadow 0.2s, transform 0.2s;
  }
  .course-card:hover { 
    box-shadow: 0 4px 16px rgba(0,0,0,0.07); 
    transform: translateY(-2px); 
  }
  .course-card h4 { font-size: 0.88rem; font-weight: 600; margin-bottom: 0.3rem; }
  .course-card p { font-size: 0.75rem; color: var(--muted); }
  .teaching-sub { font-size: 0.9rem; color: var(--muted); margin-bottom: 1.8rem; }

  /* â”€â”€ ACHIEVEMENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .ach-grid { 
    display: grid; 
    grid-template-columns: repeat(auto-fit, minmax(260px, 1fr)); 
    gap: 1rem; 
  }
  .ach-card {
    padding: 1.6rem;
    border-radius: 8px;
    transition: transform 0.2s, box-shadow 0.2s;
  }
  .ach-card:hover { 
    transform: translateY(-3px); 
    box-shadow: 0 8px 28px rgba(0,0,0,0.12); 
  }
  .ach-blue  { 
    background: linear-gradient(135deg, #1e40af 0%, #2563eb 100%); 
    color: white; 
  }
  .ach-teal  { 
    background: linear-gradient(135deg, #0f766e 0%, #0d9488 100%); 
    color: white; 
  }
  .ach-navy  { 
    background: linear-gradient(135deg, #0a1628 0%, #122040 100%); 
    color: white; 
  }
  .ach-num {
    font-family: 'DM Serif Display', serif;
    font-size: 2.4rem;
    line-height: 1;
    margin-bottom: 0.6rem;
    color: rgba(255,255,255,0.95);
  }
  .ach-desc { 
    font-size: 0.82rem; 
    color: rgba(255,255,255,0.75); 
    line-height: 1.6; 
  }

  /* â”€â”€ PEER REVIEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .review-table { width:100%; border-collapse:collapse; font-size:0.85rem; }
  .review-table th {
    text-align: left;
    padding: 0.6rem 1rem;
    font-size: 0.7rem;
    font-family: 'DM Mono', monospace;
    color: var(--muted);
    text-transform: uppercase;
    letter-spacing: 0.05em;
    border-bottom: 2px solid var(--border);
  }
  .review-table td { padding: 0.8rem 1rem; border-bottom: 1px solid var(--border); color: #334155; }
  .review-table tr:last-child td { border-bottom: none; }
  .review-table tr:hover td { background: #f8faff; }
  .review-count {
    font-family: 'DM Mono', monospace;
    font-size: 0.78rem;
    background: var(--light);
    color: var(--accent);
    padding: 0.2rem 0.6rem;
    border-radius: 3px;
    font-weight: 500;
  }
  .journal-highlight { font-weight: 600; color: var(--navy); }
  .review-orcid { margin-top: 1rem; font-size: 0.78rem; color: var(--muted); }
  .review-orcid a { color: var(--accent); font-family: monospace; text-decoration: none; }

  /* â”€â”€ CONTACT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  .contact-section { background: var(--navy) !important; border-bottom: none; }
  .contact-section .section-label { color: var(--teal); }
  .contact-section .section-title { color: white; }
  .contact-grid {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 3rem;
    align-items: start;
  }
  .contact-text { 
    font-size: 0.95rem; 
    color: rgba(255,255,255,0.62); 
    line-height: 1.8; 
    margin-bottom: 1.5rem; 
  }
  .contact-items { display:flex; flex-direction:column; gap:0.8rem; }
  .contact-item {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    font-size: 0.85rem;
    color: rgba(255,255,255,0.75);
    text-decoration: none;
    transition: color 0.2s;
  }
  .contact-item:hover { color: white; }
  .contact-icon {
    width: 32px; height: 32px;
    background: rgba(255,255,255,0.07);
    border-radius: 4px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 0.85rem;
    flex-shrink: 0;
    transition: background 0.2s;
  }
  .contact-item:hover .contact-icon { background: rgba(255,255,255,0.14); }
  .open-to {
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.09);
    border-radius: 8px;
    padding: 1.8rem;
  }
  .open-to h4 {
    font-size: 0.72rem;
    font-family: 'DM Mono', monospace;
    color: var(--teal);
    text-transform: uppercase;
    letter-spacing: 0.1em;
    margin-bottom: 1rem;
  }
  .open-to ul { list-style:none; display:flex; flex-direction:column; gap:0.6rem; }
  .open-to li {
    font-size: 0.85rem;
    color: rgba(255,255,255,0.68);
    display: flex;
    align-items: center;
    gap: 0.5rem;
  }
  .open-to li::before { content:'â†’'; color:var(--accent-light); font-size:0.75rem; }

  /* â”€â”€ FOOTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  footer {
    background: #050d1a;
    color: rgba(255,255,255,0.25);
    text-align: center;
    padding: 1.6rem;
    font-size: 0.72rem;
    font-family: 'DM Mono', monospace;
    letter-spacing: 0.03em;
  }

  /* â”€â”€ RESPONSIVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
  @media (max-width: 768px) {
    .demos-grid { grid-template-columns: 1fr; }
    .hero-inner { justify-content: center; text-align: center; }
    .hero-metrics { justify-content: center; }
    .hero-links { justify-content: center; }
    .contact-grid { grid-template-columns: 1fr; }
    .hero-metrics { gap: 1.5rem; }
    .nav-center { display: none; }
    .pub-card { grid-template-columns: 1fr; }
    .btn-cv-nav span { display: none; }
    .vision-block { grid-template-columns: 1fr; }
    .vision-pillars { flex-direction: row; flex-wrap: wrap; min-width: unset; }
  }
</style>
</head>
<body>

<!-- â”€â”€ NAV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<nav>
  <span class="nav-name">R. D. Florez-Zela</span>

  <ul class="nav-center">
    <li><a href="#about" data-i18n="nav_about">About</a></li>
    <li><a href="#vision" data-i18n="nav_vision">Vision</a></li>
    <li><a href="#research" data-i18n="nav_research">Research</a></li>
    <li><a href="#demos" data-i18n="nav_demos">Demos</a></li>
    <li><a href="#publications" data-i18n="nav_pubs">Publications</a></li>
    <li><a href="#achievements" data-i18n="nav_ach">Achievements</a></li>
    <li><a href="#contact" data-i18n="nav_contact">Contact</a></li>
  </ul>

  <div class="nav-right">
    <div class="lang-toggle">
      <button class="lang-btn active" data-lang="en" onclick="setLang('en')">EN</button>
      <button class="lang-btn" data-lang="es" onclick="setLang('es')">ES</button>
    </div>

    <a href="CV_Florez_EN.pdf" download id="cv-nav-btn" class="btn-cv-nav">
      <svg viewBox="0 0 16 16" fill="none" stroke="currentColor" stroke-width="2">
        <path d="M8 2v8M5 7l3 3 3-3"/><path d="M2 12h12"/>
      </svg>
      <span data-i18n="cv_download">Download CV</span>
    </a>
  </div>
</nav>

<!-- â”€â”€ HERO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<div class="hero">
  <div class="hero-grid"></div>
  <div class="hero-inner">
    
    <div class="profile-container">
      <div class="profile-ring">
        <img src="assets/images/profile.jpg" alt="Ruben Dario Florez-Zela" class="profile-img">
      </div>
    </div>
    
    <div class="hero-content">
      <span class="hero-tag" data-i18n="hero_tag">Computational Neuroengineering</span>
      <h1>Ruben Dario<br><span>Florez-Zela</span></h1>
      <p class="hero-subtitle" data-i18n="hero_subtitle">AI/ML for Cognitive State Monitoring in Safety-Critical Systems Â· LIECAR Lab, UNSAAC Â· Cusco, Peru</p>

      <div class="hero-metrics">
        <div class="metric">
          <div class="metric-num">143+</div>
          <div class="metric-label" data-i18n="metric_citations">Citations</div>
        </div>
        <div class="metric">
          <div class="metric-num">5</div>
          <div class="metric-label">h-index</div>
        </div>
        <div class="metric">
          <div class="metric-num">11</div>
          <div class="metric-label" data-i18n="metric_pubs">Publications</div>
        </div>
        <div class="metric">
          <div class="metric-num">13</div>
          <div class="metric-label" data-i18n="metric_reviews">Peer Reviews</div>
        </div>
      </div>

      <div class="hero-links">
        <a href="#publications" class="btn-primary" data-i18n="btn_view_pubs">View Publications</a>
        <a href="CV_Florez_EN.pdf" download id="cv-hero-btn" class="btn-cv-hero">
          <svg viewBox="0 0 16 16" fill="none" stroke="currentColor" stroke-width="2">
            <path d="M8 2v8M5 7l3 3 3-3"/><path d="M2 12h12"/>
          </svg>
          <span data-i18n="cv_download">Download CV</span>
        </a>
        <a href="#contact" class="btn-outline" data-i18n="nav_contact">Contact</a>
        <a href="https://www.linkedin.com/in/rubenflorez/" class="btn-outline" target="_blank">LinkedIn</a>
        <a href="https://orcid.org/0000-0002-9833-0213" class="btn-outline" target="_blank">ORCID</a>
      </div>
    </div>
  </div>
</div>

<!-- â”€â”€ ABOUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="about">
  <div class="section-inner">
    <div class="section-label" data-i18n="about_label">About</div>
    <div class="section-title" data-i18n="about_title">Building multimodal AI systems for real-time cognitive state monitoring in safety-critical environments</div>
    <div class="about-text">
      <p data-i18n="about_p1">I develop multimodal AI architectures that monitor human cognitive state in real time â€” with a focus on safety-critical environments where cognitive impairment directly translates to lives at risk.</p>
      <p data-i18n="about_p2">My work integrates EEG signal processing, computer vision, and deep learning to design interpretable, deployable architectures that go beyond lab prototypes: systems that run on embedded hardware, handle real-world noise, and produce outputs that can be trusted in high-stakes decisions.</p>
      <p data-i18n="about_p3">I am a researcher at the LIECAR Laboratory and lecturer at the Universidad Nacional de San Antonio Abad del Cusco (UNSAAC), Peru, recognized as a <strong>RENACYT Level V researcher</strong> by CONCYTEC. I serve as a peer reviewer for international scientific publications including <strong>Scientific Reports (Nature Portfolio)</strong> and <strong>ACM Transactions on Intelligent Systems and Technology</strong>.</p>
    </div>
    <div class="about-badges">
      <span class="badge" data-i18n="badge1">EEG Signal Processing</span>
      <span class="badge" data-i18n="badge2">Multimodal AI</span>
      <span class="badge" data-i18n="badge3">Driver Drowsiness Detection</span>
      <span class="badge" data-i18n="badge4">Embedded Deep Learning</span>
      <span class="badge">Computer Vision</span>
      <span class="badge" data-i18n="badge5">Safety-Critical Systems</span>
      <span class="badge" data-i18n="badge6">Cognitive Neuroscience</span>
    </div>
  </div>
</section>

<!-- â”€â”€ RESEARCH VISION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="vision">
  <div class="section-inner">
    <div class="section-label" data-i18n="vision_label">Vision</div>
    <div class="section-title" data-i18n="vision_title">Research Vision</div>
    <div class="vision-block">
      <div class="vision-quote">
        <p data-i18n="vision_text">My long-term goal is to develop interpretable multimodal systems that understand human cognitive vulnerability in real-world environments â€” bridging neuroengineering, deployable AI, and human-machine safety. I aim to establish a research line where physiological sensing, edge computing, and explainability converge to build systems that are not only accurate, but trustworthy enough to be deployed in vehicles, surgical suites, and control rooms.</p>
      </div>
      <div class="vision-pillars">
        <div class="pillar">
          <div class="pillar-icon">ğŸ§ </div>
          <div class="pillar-label" data-i18n="pillar1">Neuro-ocular sensing</div>
        </div>
        <div class="pillar">
          <div class="pillar-icon">âš¡</div>
          <div class="pillar-label" data-i18n="pillar2">Edge AI deployment</div>
        </div>
        <div class="pillar">
          <div class="pillar-icon">ğŸ”</div>
          <div class="pillar-label" data-i18n="pillar3">Explainable models</div>
        </div>
        <div class="pillar">
          <div class="pillar-icon">ğŸ›¡ï¸</div>
          <div class="pillar-label" data-i18n="pillar4">Safety-critical systems</div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- â”€â”€ RESEARCH INTERESTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section>
  <div class="section-inner">
    <div class="section-label" data-i18n="interests_label">Focus Areas</div>
    <div class="section-title" data-i18n="interests_title">Research Interests</div>
    <div class="interests-grid">
      <div class="interest-card">
        <h4 data-i18n="int1_title">Cognitive State Monitoring</h4>
        <p data-i18n="int1_desc">Real-time detection of drowsiness, fatigue, and mental workload in operators of safety-critical systems such as vehicles, aviation, and industrial control.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int2_title">EEG Signal Processing</h4>
        <p data-i18n="int2_desc">Biomarker extraction, artifact removal, and feature engineering from EEG signals for reliable cognitive state classification under real-world conditions.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int3_title">Multimodal AI Fusion</h4>
        <p data-i18n="int3_desc">Combining EEG, eye-tracking (RGBâ€“NIR cameras), and facial landmark dynamics for robust, redundant cognitive state inference beyond single-modality limits.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int4_title">Embedded Deep Learning</h4>
        <p data-i18n="int4_desc">Deploying CNN and hybrid models on edge platforms (NVIDIA Jetson Nano) for low-latency, on-device inference in real-world applications.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int5_title">Interpretable AI for Human Factors</h4>
        <p data-i18n="int5_desc">Moving beyond black-box models toward systems that are auditable, explainable, and reliable â€” a critical requirement for high-stakes AI deployment.</p>
      </div>
    </div>
  </div>
</section>

<!-- â”€â”€ CURRENT RESEARCH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="research">
  <div class="section-inner">
    <div class="section-label" data-i18n="research_label">Active Project</div>
    <div class="section-title" data-i18n="research_title">Current Research</div>
    <div class="research-box">
      <div class="status-pill">
        <span class="status-dot"></span>
        <span data-i18n="research_status">Active Â· Targeting Q1 2026</span>
      </div>
      <h3 data-i18n="research_h3">Multimodal Neuro-Ocular System for Driver Drowsiness Detection</h3>
      <p data-i18n="research_p1">The leading cause of fatal road accidents is not mechanical failure â€” it's cognitive impairment behind the wheel. This project develops a real-time monitoring system that detects driver drowsiness and mental fatigue by fusing EEG biomarkers, eye-tracking dynamics via RGB and NIR cameras, and facial landmark modeling.</p>
      <p data-i18n="research_p2">Signals are processed through a multimodal deep learning architecture and deployed on an NVIDIA Jetson Nano for real-time, on-vehicle inference. A key focus is interpretability â€” using attention mechanisms and saliency maps to make model decisions transparent and trustworthy for safety-critical deployment.</p>
      <div class="signal-tags">
        <span class="signal-tag">EEG Biomarkers</span>
        <span class="signal-tag">RGBâ€“NIR Eye-Tracking</span>
        <span class="signal-tag">Facial Landmarks</span>
        <span class="signal-tag">CNN Fusion</span>
        <span class="signal-tag">Jetson Nano</span>
        <span class="signal-tag">Attention Mechanisms</span>
      </div>
    </div>
  </div>
</section>

<!-- â”€â”€ RESEARCH DEMOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="demos" class="demos-section">
  <div class="section-inner">
    <div class="section-label" data-i18n="demos_label">Live Demos</div>
    <div class="section-title" data-i18n="demos_title">Research in Action</div>
    
    <div class="demos-grid">
      
      <div class="paper-divider">
        <h3>CNN-based Driver Drowsiness Detection Â· <span>82 citations</span></h3>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/1.gif" alt="NITYMED dataset evaluation" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo1_gif1_title">NITYMED Dataset Evaluation</h4>
            <span class="citation-pill">96.3%</span>
          </div>
          <p data-i18n="demo1_gif1_desc">CNN model evaluation on public NITYMED dataset. Eye closure detection with 96.3% accuracy in controlled conditions.</p>
          <div class="demo-tags">
            <span class="demo-tag">TensorFlow</span>
            <span class="demo-tag">OpenCV</span>
            <span class="demo-tag">96.3%</span>
          </div>
        </div>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/2.gif" alt="Real-world validation" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo1_gif2_title">Real-world Validation</h4>
            <span class="citation-pill">30 FPS</span>
          </div>
          <p data-i18n="demo1_gif2_desc">Validation under real lighting conditions. Robust detection at 30 FPS with varying illumination and head movements.</p>
          <div class="demo-tags">
            <span class="demo-tag">Real-time</span>
            <span class="demo-tag">Robust</span>
            <span class="demo-tag">30 FPS</span>
          </div>
        </div>
      </div>
      
      <div class="paper-divider">
        <h3>Embedded System on NVIDIA Jetson Nano Â· <span>27 citations</span></h3>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/3.gif" alt="Visual drowsiness detection on Jetson Nano" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo2_gif1_title">Visual Drowsiness Detection</h4>
            <span class="citation-pill"><15ms</span>
          </div>
          <p data-i18n="demo2_gif1_desc">Real-time eye analysis on NVIDIA Jetson Nano. Micro-sleep detection with visual alerts at <15ms latency.</p>
          <div class="demo-tags">
            <span class="demo-tag">Jetson Nano</span>
            <span class="demo-tag">TensorRT</span>
            <span class="demo-tag"><15ms</span>
          </div>
        </div>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/4.gif" alt="Yawn detection using MAR" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo2_gif2_title">Yawn Detection (MAR)</h4>
            <span class="citation-pill">MAR</span>
          </div>
          <p data-i18n="demo2_gif2_desc">Mouth Aspect Ratio (MAR) analysis for real-time fatigue detection. Integrated with facial landmark tracking.</p>
          <div class="demo-tags">
            <span class="demo-tag">MAR</span>
            <span class="demo-tag">Facial Landmarks</span>
            <span class="demo-tag">Multi-modal</span>
          </div>
        </div>
      </div>
      
    </div>
  </div>
</section>

<!-- â”€â”€ PUBLICATIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="publications">
  <div class="section-inner">
    <div class="section-label" data-i18n="pubs_label">Publications</div>
    <div class="section-title" data-i18n="pubs_title">Selected Publications</div>

    <div class="pub-filters">
      <button class="pub-filter active" data-filter="all" onclick="filterPubs('all')" data-i18n="filter_all">All</button>
      <button class="pub-filter" data-filter="cogni" onclick="filterPubs('cogni')" data-i18n="filter_cogni">Cognitive Monitoring</button>
      <button class="pub-filter" data-filter="cv" onclick="filterPubs('cv')" data-i18n="filter_cv">Computer Vision</button>
    </div>

    <div class="pub-list" id="pub-list">
      <div class="pub-card" data-category="cogni">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3390/app13137849" target="_blank">A CNN-based approach for driver drowsiness detection by real-time eye state identification</a></div>
          <div class="pub-meta">R. Florez, F. Palomino-Quispe, RJ Coaquira-Castillo et al. Â· <em>Applied Sciences</em> 13 (13), 7849 Â· 2023</div>
        </div>
        <div class="citation-badge">82 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cogni">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3390/s24196261" target="_blank">A real-time embedded system for driver drowsiness detection based on visual analysis of the eyes and mouth using CNN and mouth aspect ratio</a></div>
          <div class="pub-meta">R. Florez, F. Palomino-Quispe, AB Alvarez et al. Â· <em>Sensors</em> 24 (19), 6261 Â· 2024</div>
        </div>
        <div class="citation-badge">27 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cv">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3390/app15095040" target="_blank">Coffee-leaf diseases and pests detection based on YOLO models</a></div>
          <div class="pub-meta">J. Fragoso, C. Silva, T. Paixao, AB Alvarez, R. Florez et al. Â· <em>Applied Sciences</em> 15 (9), 5040 Â· 2025</div>
        </div>
        <div class="citation-badge">14 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cv">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3991/ijoe.v21i07.54439" target="_blank">Illumination-Robust Conjunctival Image Preprocessing for Accurate Segmentation and Anemia Detection Using Deep Learning</a></div>
          <div class="pub-meta">JH Fuentes BeingÃ³lea, F. Palomino-Quispe, JC Herrera-Levano, R. Florez et al. Â· <em>iJOE</em> 21 (7) Â· 2025</div>
        </div>
        <div class="citation-badge">1 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cv">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.1109/INTERCON52678.2021.9532881" target="_blank">Low-cost mini humanoid robot mechanical design for mini humanoid robot contest Intercon 2021</a></div>
          <div class="pub-meta">R. Vilavita, F. Justo, R. Florez, N. Figueroa Â· <em>IEEE XXVIII Intercon</em> Â· 2021</div>
        </div>
        <div class="citation-badge">5 <span data-i18n="cit">citations</span></div>
      </div>
    </div>
    
    <p class="pub-footer">
      <span data-i18n="pubs_full_list">Full list on</span>
      <a href="https://scholar.google.com/citations?user=Xf8JgfsAAAAJ&hl" target="_blank">Google Scholar</a> Â·
      <a href="https://www.researchgate.net/profile/Ruben-Florez-Zela" target="_blank">ResearchGate</a>
    </p>
  </div>
</section>

<!-- â”€â”€ TEACHING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="teaching">
  <div class="section-inner">
    <div class="section-label" data-i18n="teaching_label">Teaching</div>
    <div class="section-title" data-i18n="teaching_title">Teaching Experience</div>
    <p class="teaching-sub" data-i18n="teaching_sub">Universidad Nacional de San Antonio Abad del Cusco (UNSAAC) Â· School of Electronic Engineering Â· April 2024 â€“ Present</p>
    <div class="teaching-grid">
      <div class="course-card">
        <h4 data-i18n="course1">Artificial Intelligence</h4>
        <p data-i18n="course_level">Undergraduate Â· Electronic Engineering</p>
      </div>
      <div class="course-card">
        <h4 data-i18n="course2">Digital Image Processing</h4>
        <p data-i18n="course_level">Undergraduate Â· Electronic Engineering</p>
      </div>
      <div class="course-card">
        <h4 data-i18n="course3">Robotics</h4>
        <p data-i18n="course_level">Undergraduate Â· Electronic Engineering</p>
      </div>
      <div class="course-card">
        <h4 data-i18n="course4">Electronics Laboratory</h4>
        <p data-i18n="course_level">Undergraduate Â· Electronic Engineering</p>
      </div>
    </div>
  </div>
</section>

<!-- â”€â”€ SELECTED ACHIEVEMENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="achievements">
  <div class="section-inner">
    <div class="section-label" data-i18n="ach_label">Achievements</div>
    <div class="section-title" data-i18n="ach_title">Selected Achievements</div>
    <div class="ach-grid">
      <div class="ach-card ach-blue">
        <div class="ach-num">143+</div>
        <div class="ach-desc" data-i18n="ach1">Total citations â€” one paper surpassing 82 citations within 2 years</div>
      </div>
      <div class="ach-card ach-teal">
        <div class="ach-num">#1</div>
        <div class="ach-desc" data-i18n="ach2">Most cited paper on real-time CNN-based eye-state drowsiness detection â€” 82 citations</div>
      </div>
      <div class="ach-card ach-navy">
        <div class="ach-num">V</div>
        <div class="ach-desc" data-i18n="ach3">RENACYT Level V researcher â€” CONCYTEC national recognition</div>
      </div>
      <div class="ach-card ach-blue">
        <div class="ach-num">7+</div>
        <div class="ach-desc" data-i18n="ach4">Active peer reviewer for international journals including ACM TIST and Scientific Reports</div>
      </div>
      <div class="ach-card ach-teal">
        <div class="ach-num">ğŸ†Ã—3</div>
        <div class="ach-desc" data-i18n="ach5">First place in regional/national competitions including First Andean Hackathon (6 countries)</div>
      </div>
      <div class="ach-card ach-navy">
        <div class="ach-num">Q1</div>
        <div class="ach-desc" data-i18n="ach6">Target submission 2026 â€” multimodal neuro-ocular system to high-impact journal</div>
      </div>
    </div>
  </div>
</section>

<!-- â”€â”€ PEER REVIEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section>
  <div class="section-inner">
    <div class="section-label" data-i18n="review_label">Peer Review</div>
    <div class="section-title" data-i18n="review_title">Peer Review Activity</div>
    <table class="review-table">
      <thead>
        <tr>
          <th data-i18n="review_th1">Journal</th>
          <th data-i18n="review_th2">Publisher</th>
          <th data-i18n="review_th3">Reviews</th>
        </tr>
      </thead>
      <tbody>
        <tr><td class="journal-highlight">Scientific Reports</td><td>Nature Portfolio</td><td><span class="review-count">2</span></td></tr>
        <tr><td class="journal-highlight">ACM Trans. on Intelligent Systems and Technology</td><td>ACM</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Journal of Ambient Intelligence and Humanized Computing</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Discover Applied Sciences</td><td>Springer</td><td><span class="review-count">3</span></td></tr>
        <tr><td>Discover Artificial Intelligence</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Discover Electronics</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Discover Internet of Things</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>IAES Int'l Journal of Artificial Intelligence</td><td>IAES</td><td><span class="review-count">2</span></td></tr>
        <tr><td>Indian Journal of Science and Technology</td><td>IJST</td><td><span class="review-count">1</span></td></tr>
      </tbody>
    </table>
    <p class="review-orcid">
      <span data-i18n="review_orcid_note">Verified via ORCID iD:</span>
      <a href="https://orcid.org/0000-0002-9833-0213" target="_blank">0000-0002-9833-0213</a>
    </p>
  </div>
</section>

<!-- â”€â”€ CONTACT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<section id="contact" class="contact-section">
  <div class="section-inner">
    <div class="section-label" data-i18n="contact_label">Contact</div>
    <div class="section-title" data-i18n="contact_title">Get in Touch</div>
    <div class="contact-grid">
      <div>
        <p class="contact-text" data-i18n="contact_text">I am open to research collaborations, dataset sharing, joint publications, academic exchanges, and PhD opportunities in neuroengineering, human factors AI, or safety-critical systems.</p>
        <div class="contact-items">
          <a href="mailto:rubendfz2206@gmail.com" class="contact-item">
            <span class="contact-icon">âœ‰</span>rubendfz2206@gmail.com
          </a>
          <a href="https://www.linkedin.com/in/rubenflorez/" class="contact-item" target="_blank">
            <span class="contact-icon">in</span>linkedin.com/in/rubenflorez
          </a>
          <a href="https://orcid.org/0000-0002-9833-0213" class="contact-item" target="_blank">
            <span class="contact-icon">ID</span>ORCID 0000-0002-9833-0213
          </a>
          <a href="https://scholar.google.com/citations?user=Xf8JgfsAAAAJ&hl" class="contact-item" target="_blank">
            <span class="contact-icon">GS</span>Google Scholar
          </a>
          <a href="https://www.researchgate.net/profile/Ruben-Florez-Zela" class="contact-item" target="_blank">
            <span class="contact-icon">RG</span>ResearchGate
          </a>
        </div>
      </div>
      <div class="open-to">
        <h4 data-i18n="open_title">Open to</h4>
        <ul>
          <li data-i18n="open1">Research collaborations</li>
          <li data-i18n="open2">Dataset sharing</li>
          <li data-i18n="open3">Joint publications</li>
          <li data-i18n="open4">Academic exchanges</li>
          <li data-i18n="open5">PhD opportunities</li>
          <li data-i18n="open6">Industry partnerships</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<!-- â”€â”€ FOOTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
<footer>
  <span data-i18n="footer">Â© 2025 Ruben Dario Florez-Zela Â· UNSAAC Â· Cusco, Peru</span>
</footer>

<script>
function filterPubs(category) {
  document.querySelectorAll('.pub-card').forEach(card => {
    if (category === 'all') {
      card.classList.remove('hidden');
    } else {
      if (card.dataset.category === category) {
        card.classList.remove('hidden');
      } else {
        card.classList.add('hidden');
      }
    }
  });
  
  document.querySelectorAll('.pub-filter').forEach(btn => {
    if (btn.dataset.filter === category) {
      btn.classList.add('active');
    } else {
      btn.classList.remove('active');
    }
  });
}

const translations = {
  en: {
    "nav_about": "About",
    "nav_vision": "Vision",
    "nav_research": "Research",
    "nav_demos": "Demos",
    "nav_pubs": "Publications",
    "nav_ach": "Achievements",
    "nav_contact": "Contact",
    "cv_download": "Download CV",
    "hero_tag": "Computational Neuroengineering",
    "hero_subtitle": "AI/ML for Cognitive State Monitoring in Safety-Critical Systems Â· LIECAR Lab, UNSAAC Â· Cusco, Peru",
    "metric_citations": "Citations",
    "metric_pubs": "Publications",
    "metric_reviews": "Peer Reviews",
    "btn_view_pubs": "View Publications",
    "about_label": "About",
    "about_title": "Building multimodal AI systems for real-time cognitive state monitoring in safety-critical environments",
    "about_p1": "I develop multimodal AI architectures that monitor human cognitive state in real time â€” with a focus on safety-critical environments where cognitive impairment directly translates to lives at risk.",
    "about_p2": "My work integrates EEG signal processing, computer vision, and deep learning to design interpretable, deployable architectures that go beyond lab prototypes: systems that run on embedded hardware, handle real-world noise, and produce outputs that can be trusted in high-stakes decisions.",
    "about_p3": "I am a researcher at the LIECAR Laboratory and lecturer at the Universidad Nacional de San Antonio Abad del Cusco (UNSAAC), Peru, recognized as a <strong>RENACYT Level V researcher</strong> by CONCYTEC. I serve as a peer reviewer for international scientific publications including <strong>Scientific Reports (Nature Portfolio)</strong> and <strong>ACM Transactions on Intelligent Systems and Technology</strong>.",
    "badge1": "EEG Signal Processing",
    "badge2": "Multimodal AI",
    "badge3": "Driver Drowsiness Detection",
    "badge4": "Embedded Deep Learning",
    "badge5": "Safety-Critical Systems",
    "badge6": "Cognitive Neuroscience",
    "vision_label": "Vision",
    "vision_title": "Research Vision",
    "vision_text": "My long-term goal is to develop interpretable multimodal systems that understand human cognitive vulnerability in real-world environments â€” bridging neuroengineering, deployable AI, and human-machine safety. I aim to establish a research line where physiological sensing, edge computing, and explainability converge to build systems that are not only accurate, but trustworthy enough to be deployed in vehicles, surgical suites, and control rooms.",
    "pillar1": "Neuro-ocular sensing",
    "pillar2": "Edge AI deployment",
    "pillar3": "Explainable models",
    "pillar4": "Safety-critical systems",
    "interests_label": "Focus Areas",
    "interests_title": "Research Interests",
    "int1_title": "Cognitive State Monitoring",
    "int1_desc": "Real-time detection of drowsiness, fatigue, and mental workload in operators of safety-critical systems such as vehicles, aviation, and industrial control.",
    "int2_title": "EEG Signal Processing",
    "int2_desc": "Biomarker extraction, artifact removal, and feature engineering from EEG signals for reliable cognitive state classification under real-world conditions.",
    "int3_title": "Multimodal AI Fusion",
    "int3_desc": "Combining EEG, eye-tracking (RGBâ€“NIR cameras), and facial landmark dynamics for robust, redundant cognitive state inference beyond single-modality limits.",
    "int4_title": "Embedded Deep Learning",
    "int4_desc": "Deploying CNN and hybrid models on edge platforms (NVIDIA Jetson Nano) for low-latency, on-device inference in real-world applications.",
    "int5_title": "Interpretable AI for Human Factors",
    "int5_desc": "Moving beyond black-box models toward systems that are auditable, explainable, and reliable â€” a critical requirement for high-stakes AI deployment.",
    "research_label": "Active Project",
    "research_title": "Current Research",
    "research_status": "Active Â· Targeting Q1 2026",
    "research_h3": "Multimodal Neuro-Ocular System for Driver Drowsiness Detection",
    "research_p1": "The leading cause of fatal road accidents is not mechanical failure â€” it's cognitive impairment behind the wheel. This project develops a real-time monitoring system that detects driver drowsiness and mental fatigue by fusing EEG biomarkers, eye-tracking dynamics via RGB and NIR cameras, and facial landmark modeling.",
    "research_p2": "Signals are processed through a multimodal deep learning architecture and deployed on an NVIDIA Jetson Nano for real-time, on-vehicle inference. A key focus is interpretability â€” using attention mechanisms and saliency maps to make model decisions transparent and trustworthy for safety-critical deployment.",
    "demos_label": "Live Demos",
    "demos_title": "Research in Action",
    "demo1_gif1_title": "NITYMED Dataset Evaluation",
    "demo1_gif1_desc": "CNN model evaluation on public NITYMED dataset. Eye closure detection with 96.3% accuracy in controlled conditions.",
    "demo1_gif2_title": "Real-world Validation",
    "demo1_gif2_desc": "Validation under real lighting conditions. Robust detection at 30 FPS with varying illumination and head movements.",
    "demo2_gif1_title": "Visual Drowsiness Detection",
    "demo2_gif1_desc": "Real-time eye analysis on NVIDIA Jetson Nano. Micro-sleep detection with visual alerts at <15ms latency.",
    "demo2_gif2_title": "Yawn Detection (MAR)",
    "demo2_gif2_desc": "Mouth Aspect Ratio (MAR) analysis for real-time fatigue detection. Integrated with facial landmark tracking.",
    "pubs_label": "Publications",
    "pubs_title": "Selected Publications",
    "pubs_full_list": "Full list on",
    "filter_all": "All",
    "filter_cogni": "Cognitive Monitoring",
    "filter_cv": "Computer Vision",
    "cit": "citations",
    "teaching_label": "Teaching",
    "teaching_title": "Teaching Experience",
    "teaching_sub": "Universidad Nacional de San Antonio Abad del Cusco (UNSAAC) Â· School of Electronic Engineering Â· April 2024 â€“ Present",
    "course1": "Artificial Intelligence",
    "course2": "Digital Image Processing",
    "course3": "Robotics",
    "course4": "Electronics Laboratory",
    "course_level": "Undergraduate Â· Electronic Engineering",
    "ach_label": "Achievements",
    "ach_title": "Selected Achievements",
    "ach1": "Total citations â€” one paper surpassing 82 citations within 2 years",
    "ach2": "Most cited paper on real-time CNN-based eye-state drowsiness detection â€” 82 citations",
    "ach3": "RENACYT Level V researcher â€” CONCYTEC national recognition",
    "ach4": "Active peer reviewer for international journals including ACM TIST and Scientific Reports",
    "ach5": "First place in regional/national competitions including First Andean Hackathon (6 countries)",
    "ach6": "Target submission 2026 â€” multimodal neuro-ocular system to high-impact journal",
    "review_label": "Peer Review",
    "review_title": "Peer Review Activity",
    "review_th1": "Journal",
    "review_th2": "Publisher",
    "review_th3": "Reviews",
    "review_orcid_note": "Verified via ORCID iD:",
    "contact_label": "Contact",
    "contact_title": "Get in Touch",
    "contact_text": "I am open to research collaborations, dataset sharing, joint publications, academic exchanges, and PhD opportunities in neuroengineering, human factors AI, or safety-critical systems.",
    "open_title": "Open to",
    "open1": "Research collaborations",
    "open2": "Dataset sharing",
    "open3": "Joint publications",
    "open4": "Academic exchanges",
    "open5": "PhD opportunities",
    "open6": "Industry partnerships",
    "footer": "Â© 2025 Ruben Dario Florez-Zela Â· UNSAAC Â· Cusco, Peru"
  },
  es: {
    "nav_about": "Sobre mÃ­",
    "nav_vision": "VisiÃ³n",
    "nav_research": "InvestigaciÃ³n",
    "nav_demos": "Demos",
    "nav_pubs": "Publicaciones",
    "nav_ach": "Logros",
    "nav_contact": "Contacto",
    "cv_download": "Descargar CV",
    "hero_tag": "NeuroingenierÃ­a Computacional",
    "hero_subtitle": "IA/ML para Monitoreo del Estado Cognitivo en Sistemas de Alta Seguridad Â· Lab. LIECAR, UNSAAC Â· Cusco, PerÃº",
    "metric_citations": "Citas",
    "metric_pubs": "Publicaciones",
    "metric_reviews": "Revisiones",
    "btn_view_pubs": "Ver Publicaciones",
    "about_label": "Sobre mÃ­",
    "about_title": "Construyendo sistemas de IA multimodal para monitoreo cognitivo en tiempo real en entornos de alta seguridad",
    "about_p1": "Desarrollo arquitecturas de IA multimodal que monitorean el estado cognitivo humano en tiempo real, con enfoque en entornos de alta seguridad donde el deterioro cognitivo se traduce directamente en vidas en riesgo.",
    "about_p2": "Mi trabajo integra procesamiento de seÃ±ales EEG, visiÃ³n computacional y aprendizaje profundo para diseÃ±ar arquitecturas interpretables y desplegables que van mÃ¡s allÃ¡ de los prototipos de laboratorio: sistemas que operan en hardware embebido, manejan ruido del mundo real y generan salidas confiables para decisiones crÃ­ticas.",
    "about_p3": "Soy investigador en el Laboratorio LIECAR y docente de la Universidad Nacional de San Antonio Abad del Cusco (UNSAAC), PerÃº, reconocido como <strong>Investigador RENACYT Nivel V</strong> por CONCYTEC. Ejerzo como revisor de publicaciones cientÃ­ficas internacionales incluyendo <strong>Scientific Reports (Nature Portfolio)</strong> y <strong>ACM Transactions on Intelligent Systems and Technology</strong>.",
    "badge1": "Procesamiento de SeÃ±ales EEG",
    "badge2": "IA Multimodal",
    "badge3": "DetecciÃ³n de Somnolencia",
    "badge4": "Deep Learning Embebido",
    "badge5": "Sistemas de Alta Seguridad",
    "badge6": "Neurociencia Cognitiva",
    "vision_label": "VisiÃ³n",
    "vision_title": "VisiÃ³n de InvestigaciÃ³n",
    "vision_text": "Mi objetivo a largo plazo es desarrollar sistemas multimodales interpretables que comprendan la vulnerabilidad cognitiva humana en entornos reales â€” conectando la neuroingenierÃ­a, la IA desplegable y la seguridad humano-mÃ¡quina. Busco establecer una lÃ­nea de investigaciÃ³n donde la detecciÃ³n fisiolÃ³gica, la computaciÃ³n en el borde y la explicabilidad converjan para construir sistemas que no solo sean precisos, sino lo suficientemente confiables para desplegarse en vehÃ­culos, quirÃ³fanos y salas de control.",
    "pillar1": "DetecciÃ³n neuro-ocular",
    "pillar2": "IA en el borde (Edge)",
    "pillar3": "Modelos explicables",
    "pillar4": "Sistemas de alta seguridad",
    "interests_label": "Ãreas de Enfoque",
    "interests_title": "Intereses de InvestigaciÃ³n",
    "int1_title": "Monitoreo del Estado Cognitivo",
    "int1_desc": "DetecciÃ³n en tiempo real de somnolencia, fatiga y carga mental en operadores de sistemas crÃ­ticos como vehÃ­culos, aviaciÃ³n y control industrial.",
    "int2_title": "Procesamiento de SeÃ±ales EEG",
    "int2_desc": "ExtracciÃ³n de biomarcadores, eliminaciÃ³n de artefactos e ingenierÃ­a de caracterÃ­sticas a partir de seÃ±ales EEG para clasificaciÃ³n confiable del estado cognitivo en condiciones reales.",
    "int3_title": "FusiÃ³n Multimodal de IA",
    "int3_desc": "CombinaciÃ³n de EEG, seguimiento ocular (cÃ¡maras RGBâ€“NIR) y dinÃ¡micas de puntos de referencia faciales para inferencia robusta y redundante del estado cognitivo.",
    "int4_title": "Deep Learning Embebido",
    "int4_desc": "Despliegue de modelos CNN e hÃ­bridos en plataformas de borde (NVIDIA Jetson Nano) para inferencia en dispositivo con baja latencia en aplicaciones reales.",
    "int5_title": "IA Interpretable para Factores Humanos",
    "int5_desc": "Avanzar mÃ¡s allÃ¡ de los modelos de caja negra hacia sistemas auditables, explicables y confiables â€” requisito crÃ­tico para el despliegue de IA en entornos de alto riesgo.",
    "research_label": "Proyecto Activo",
    "research_title": "InvestigaciÃ³n Actual",
    "research_status": "Activo Â· EnvÃ­o objetivo Q1 2026",
    "research_h3": "Sistema Neuro-Ocular Multimodal para DetecciÃ³n de Somnolencia en Conductores",
    "research_p1": "La principal causa de accidentes fatales de trÃ¡nsito no es el fallo mecÃ¡nico â€” es el deterioro cognitivo al volante. Este proyecto desarrolla un sistema de monitoreo en tiempo real que detecta somnolencia y fatiga mental fusionando biomarcadores EEG, dinÃ¡micas de seguimiento ocular mediante cÃ¡maras RGB y NIR, y modelado de puntos de referencia faciales.",
    "research_p2": "Las seÃ±ales se procesan mediante una arquitectura de aprendizaje profundo multimodal y se despliegan en un NVIDIA Jetson Nano para inferencia en tiempo real a bordo del vehÃ­culo. Un enfoque clave es la interpretabilidad â€” usando mecanismos de atenciÃ³n y mapas de prominencia para hacer transparentes y confiables las decisiones del modelo en despliegues crÃ­ticos.",
    "demos_label": "Demostraciones",
    "demos_title": "InvestigaciÃ³n en AcciÃ³n",
    "demo1_gif1_title": "EvaluaciÃ³n en Dataset NITYMED",
    "demo1_gif1_desc": "EvaluaciÃ³n del modelo CNN en dataset pÃºblico NITYMED. DetecciÃ³n de ojos cerrados con 96.3% de precisiÃ³n en condiciones controladas.",
    "demo1_gif2_title": "ValidaciÃ³n en Entorno Real",
    "demo1_gif2_desc": "ValidaciÃ³n en condiciones reales de iluminaciÃ³n. DetecciÃ³n robusta a 30 FPS con variaciones de luz y movimiento.",
    "demo2_gif1_title": "DetecciÃ³n Visual de Somnolencia",
    "demo2_gif1_desc": "AnÃ¡lisis de ojos en tiempo real en NVIDIA Jetson Nano. DetecciÃ³n de micro-sueÃ±os con alertas visuales a <15ms de latencia.",
    "demo2_gif2_title": "DetecciÃ³n de Bostezos (MAR)",
    "demo2_gif2_desc": "AnÃ¡lisis de Mouth Aspect Ratio (MAR) para detecciÃ³n de fatiga en tiempo real. Integrado con seguimiento de puntos faciales.",
    "pubs_label": "Publicaciones",
    "pubs_title": "Publicaciones Seleccionadas",
    "pubs_full_list": "Lista completa en",
    "filter_all": "Todas",
    "filter_cogni": "Monitoreo Cognitivo",
    "filter_cv": "VisiÃ³n Computacional",
    "cit": "citas",
    "teaching_label": "Docencia",
    "teaching_title": "Experiencia Docente",
    "teaching_sub": "Universidad Nacional de San Antonio Abad del Cusco (UNSAAC) Â· Escuela de IngenierÃ­a ElectrÃ³nica Â· Abril 2024 â€“ Presente",
    "course1": "Inteligencia Artificial",
    "course2": "Procesamiento Digital de ImÃ¡genes",
    "course3": "RobÃ³tica",
    "course4": "Laboratorio de ElectrÃ³nica",
    "course_level": "Pregrado Â· IngenierÃ­a ElectrÃ³nica",
    "ach_label": "Logros",
    "ach_title": "Logros Destacados",
    "ach1": "Citas totales â€” un artÃ­culo superÃ³ 82 citas en 2 aÃ±os",
    "ach2": "ArtÃ­culo mÃ¡s citado en detecciÃ³n de somnolencia CNN en tiempo real â€” 82 citas",
    "ach3": "Investigador RENACYT Nivel V â€” reconocimiento nacional CONCYTEC",
    "ach4": "Revisor activo para revistas internacionales incluyendo ACM TIST y Scientific Reports",
    "ach5": "Primer lugar en competencias regionales/nacionales incluyendo Primera Hackathon Andina (6 paÃ­ses)",
    "ach6": "EnvÃ­o objetivo 2026 â€” sistema neuro-ocular multimodal a revista de alto impacto",
    "review_label": "RevisiÃ³n por Pares",
    "review_title": "Actividad como Revisor",
    "review_th1": "Revista",
    "review_th2": "Editorial",
    "review_th3": "Revisiones",
    "review_orcid_note": "Verificado vÃ­a ORCID iD:",
    "contact_label": "Contacto",
    "contact_title": "Ponerse en Contacto",
    "contact_text": "Estoy abierto a colaboraciones de investigaciÃ³n, intercambio de datos, publicaciones conjuntas, intercambios acadÃ©micos y oportunidades de doctorado en neuroingenierÃ­a, IA para factores humanos o sistemas de alta seguridad.",
    "open_title": "Disponible para",
    "open1": "Colaboraciones de investigaciÃ³n",
    "open2": "Intercambio de datasets",
    "open3": "Publicaciones conjuntas",
    "open4": "Intercambios acadÃ©micos",
    "open5": "Oportunidades de doctorado",
    "open6": "Alianzas con la industria",
    "footer": "Â© 2025 Ruben Dario Florez-Zela Â· UNSAAC Â· Cusco, PerÃº"
  }
};

let currentLang = 'en';

function setLang(lang) {
  currentLang = lang;
  const t = translations[lang];

  document.querySelectorAll('[data-i18n]').forEach(el => {
    const key = el.dataset.i18n;
    if (t[key] !== undefined) el.innerHTML = t[key];
  });

  document.querySelectorAll('.lang-btn').forEach(btn => {
    btn.classList.toggle('active', btn.dataset.lang === lang);
  });

  const cvFile = lang === 'es' ? 'CV_Florez_ES.pdf' : 'CV_Florez_EN.pdf';
  document.getElementById('cv-nav-btn').href = cvFile;
  document.getElementById('cv-hero-btn').href = cvFile;

  document.documentElement.lang = lang;
}

document.addEventListener('DOMContentLoaded', function() {
  setLang('en');
});
</script>

</body>
</html>
