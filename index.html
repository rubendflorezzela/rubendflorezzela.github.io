<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ruben Dario Florez-Zela ¬∑ Computational Neuroengineering Researcher</title>
<link href="https://fonts.googleapis.com/css2?family=DM+Serif+Display:ital@0;1&family=DM+Sans:opsz,wght@9..40,300;9..40,400;9..40,500;9..40,600&family=DM+Mono:wght@400;500&display=swap" rel="stylesheet">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD2HQJ1XRK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FD2HQJ1XRK');
</script>

<!-- CSS Principal -->
<link rel="stylesheet" href="css/style.css">
</head>
<body>

<!-- ‚îÄ‚îÄ NAV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<nav>
  <span class="nav-name">R. D. Florez-Zela</span>

  <ul class="nav-center">
    <li><a href="#about" data-i18n="nav_about">About</a></li>
    <li><a href="#vision" data-i18n="nav_vision">Vision</a></li>
    <li><a href="#research" data-i18n="nav_research">Research</a></li>
    <li><a href="#demos" data-i18n="nav_demos">Demos</a></li>
    <li><a href="#publications" data-i18n="nav_pubs">Publications</a></li>
    <li><a href="#achievements" data-i18n="nav_ach">Achievements</a></li>
    <li><a href="#contact" data-i18n="nav_contact">Contact</a></li>
  </ul>

  <div class="nav-right">
    <div class="lang-toggle">
      <button class="lang-btn active" data-lang="en" onclick="setLang('en')">EN</button>
      <button class="lang-btn" data-lang="es" onclick="setLang('es')">ES</button>
    </div>

    <a href="CV_Florez_EN.pdf" download id="cv-nav-btn" class="btn-cv-nav">
      <svg viewBox="0 0 16 16" fill="none" stroke="currentColor" stroke-width="2">
        <path d="M8 2v8M5 7l3 3 3-3"/><path d="M2 12h12"/>
      </svg>
      <span data-i18n="cv_download">Download CV</span>
    </a>
  </div>
</nav>

<!-- ‚îÄ‚îÄ HERO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<div class="hero">
  <div class="hero-grid"></div>
  <div class="hero-inner">
    
    <div class="profile-container">
      <div class="profile-ring">
        <img src="assets/images/profile.jpg" alt="Ruben Dario Florez-Zela" class="profile-img">
      </div>
    </div>
    
    <div class="hero-content">
      <span class="hero-tag" data-i18n="hero_tag">Computational Neuroengineering</span>
      <h1>Ruben Dario<br><span>Florez-Zela</span></h1>
      <p class="hero-subtitle" data-i18n="hero_subtitle">AI/ML for Cognitive State Monitoring in Safety-Critical Systems ¬∑ LIECAR Lab, UNSAAC ¬∑ Cusco, Peru</p>

      <div class="hero-metrics">
        <div class="metric">
          <div class="metric-num">143+</div>
          <div class="metric-label" data-i18n="metric_citations">Citations</div>
        </div>
        <div class="metric">
          <div class="metric-num">5</div>
          <div class="metric-label">h-index</div>
        </div>
        <div class="metric">
          <div class="metric-num">11</div>
          <div class="metric-label" data-i18n="metric_pubs">Publications</div>
        </div>
        <div class="metric">
          <div class="metric-num">13</div>
          <div class="metric-label" data-i18n="metric_reviews">Peer Reviews</div>
        </div>
      </div>

      <div class="hero-links">
        <a href="#publications" class="btn-primary" data-i18n="btn_view_pubs">View Publications</a>
        <a href="CV_Florez_EN.pdf" download id="cv-hero-btn" class="btn-cv-hero">
          <svg viewBox="0 0 16 16" fill="none" stroke="currentColor" stroke-width="2">
            <path d="M8 2v8M5 7l3 3 3-3"/><path d="M2 12h12"/>
          </svg>
          <span data-i18n="cv_download">Download CV</span>
        </a>
        <a href="#contact" class="btn-outline" data-i18n="nav_contact">Contact</a>
        <a href="https://www.linkedin.com/in/rubenflorez/" class="btn-outline" target="_blank">LinkedIn</a>
        <a href="https://orcid.org/0000-0002-9833-0213" class="btn-outline" target="_blank">ORCID</a>
      </div>
    </div>
  </div>
</div>

<!-- ‚îÄ‚îÄ ABOUT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="about">
  <div class="section-inner">
    <div class="section-label" data-i18n="about_label">About</div>
    <div class="section-title" data-i18n="about_title">Building multimodal AI systems for real-time cognitive state monitoring in safety-critical environments</div>
    <div class="about-text">
      <p data-i18n="about_p1">I develop multimodal AI architectures that monitor human cognitive state in real time ‚Äî with a focus on safety-critical environments where cognitive impairment directly translates to lives at risk.</p>
      <p data-i18n="about_p2">My work integrates EEG signal processing, computer vision, and deep learning to design interpretable, deployable architectures that go beyond lab prototypes: systems that run on embedded hardware, handle real-world noise, and produce outputs that can be trusted in high-stakes decisions.</p>
      <p data-i18n="about_p3">I am a researcher at the LIECAR Laboratory and lecturer at the Universidad Nacional de San Antonio Abad del Cusco (UNSAAC), Peru, recognized as a <strong>RENACYT Level V researcher</strong> by CONCYTEC. I serve as a peer reviewer for international scientific publications including <strong>Scientific Reports (Nature Portfolio)</strong> and <strong>ACM Transactions on Intelligent Systems and Technology</strong>.</p>
    </div>
    <div class="about-badges">
      <span class="badge" data-i18n="badge1">EEG Signal Processing</span>
      <span class="badge" data-i18n="badge2">Multimodal AI</span>
      <span class="badge" data-i18n="badge3">Driver Drowsiness Detection</span>
      <span class="badge" data-i18n="badge4">Embedded Deep Learning</span>
      <span class="badge">Computer Vision</span>
      <span class="badge" data-i18n="badge5">Safety-Critical Systems</span>
      <span class="badge" data-i18n="badge6">Cognitive Neuroscience</span>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ RESEARCH VISION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="vision">
  <div class="section-inner">
    <div class="section-label" data-i18n="vision_label">Vision</div>
    <div class="section-title" data-i18n="vision_title">Research Vision</div>
    <div class="vision-block">
      <div class="vision-quote">
        <p data-i18n="vision_text">My long-term goal is to develop interpretable multimodal systems that understand human cognitive vulnerability in real-world environments ‚Äî bridging neuroengineering, deployable AI, and human-machine safety. I aim to establish a research line where physiological sensing, edge computing, and explainability converge to build systems that are not only accurate, but trustworthy enough to be deployed in vehicles, surgical suites, and control rooms.</p>
      </div>
      <div class="vision-pillars">
        <div class="pillar">
          <div class="pillar-icon">üß†</div>
          <div class="pillar-label" data-i18n="pillar1">Neuro-ocular sensing</div>
        </div>
        <div class="pillar">
          <div class="pillar-icon">‚ö°</div>
          <div class="pillar-label" data-i18n="pillar2">Edge AI deployment</div>
        </div>
        <div class="pillar">
          <div class="pillar-icon">üîç</div>
          <div class="pillar-label" data-i18n="pillar3">Explainable models</div>
        </div>
        <div class="pillar">
          <div class="pillar-icon">üõ°Ô∏è</div>
          <div class="pillar-label" data-i18n="pillar4">Safety-critical systems</div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ RESEARCH INTERESTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section>
  <div class="section-inner">
    <div class="section-label" data-i18n="interests_label">Focus Areas</div>
    <div class="section-title" data-i18n="interests_title">Research Interests</div>
    <div class="interests-grid">
      <div class="interest-card">
        <h4 data-i18n="int1_title">Cognitive State Monitoring</h4>
        <p data-i18n="int1_desc">Real-time detection of drowsiness, fatigue, and mental workload in operators of safety-critical systems such as vehicles, aviation, and industrial control.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int2_title">EEG Signal Processing</h4>
        <p data-i18n="int2_desc">Biomarker extraction, artifact removal, and feature engineering from EEG signals for reliable cognitive state classification under real-world conditions.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int3_title">Multimodal AI Fusion</h4>
        <p data-i18n="int3_desc">Combining EEG, eye-tracking (RGB‚ÄìNIR cameras), and facial landmark dynamics for robust, redundant cognitive state inference beyond single-modality limits.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int4_title">Embedded Deep Learning</h4>
        <p data-i18n="int4_desc">Deploying CNN and hybrid models on edge platforms (NVIDIA Jetson Nano) for low-latency, on-device inference in real-world applications.</p>
      </div>
      <div class="interest-card">
        <h4 data-i18n="int5_title">Interpretable AI for Human Factors</h4>
        <p data-i18n="int5_desc">Moving beyond black-box models toward systems that are auditable, explainable, and reliable ‚Äî a critical requirement for high-stakes AI deployment.</p>
      </div>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ CURRENT RESEARCH ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="research">
  <div class="section-inner">
    <div class="section-label" data-i18n="research_label">Active Project</div>
    <div class="section-title" data-i18n="research_title">Current Research</div>
    <div class="research-box">
      <div class="status-pill">
        <span class="status-dot"></span>
        <span data-i18n="research_status">Active ¬∑ Targeting Q1 2026</span>
      </div>
      <h3 data-i18n="research_h3">Multimodal Neuro-Ocular System for Driver Drowsiness Detection</h3>
      <p data-i18n="research_p1">The leading cause of fatal road accidents is not mechanical failure ‚Äî it's cognitive impairment behind the wheel. This project develops a real-time monitoring system that detects driver drowsiness and mental fatigue by fusing EEG biomarkers, eye-tracking dynamics via RGB and NIR cameras, and facial landmark modeling.</p>
      <p data-i18n="research_p2">Signals are processed through a multimodal deep learning architecture and deployed on an NVIDIA Jetson Nano for real-time, on-vehicle inference. A key focus is interpretability ‚Äî using attention mechanisms and saliency maps to make model decisions transparent and trustworthy for safety-critical deployment.</p>
      <div class="signal-tags">
        <span class="signal-tag">EEG Biomarkers</span>
        <span class="signal-tag">RGB‚ÄìNIR Eye-Tracking</span>
        <span class="signal-tag">Facial Landmarks</span>
        <span class="signal-tag">CNN Fusion</span>
        <span class="signal-tag">Jetson Nano</span>
        <span class="signal-tag">Attention Mechanisms</span>
      </div>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ RESEARCH DEMOS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="demos" class="demos-section">
  <div class="section-inner">
    <div class="section-label" data-i18n="demos_label">Live Demos</div>
    <div class="section-title" data-i18n="demos_title">Research in Action</div>
    
    <div class="demos-grid">
      
      <div class="paper-divider">
        <h3>CNN-based Driver Drowsiness Detection ¬∑ <span>82 citations</span></h3>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/1.gif" alt="NITYMED dataset evaluation" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo1_gif1_title">NITYMED Dataset Evaluation</h4>
            <span class="citation-pill">96.3%</span>
          </div>
          <p data-i18n="demo1_gif1_desc">CNN model evaluation on public NITYMED dataset. Eye closure detection with 96.3% accuracy in controlled conditions.</p>
          <div class="demo-tags">
            <span class="demo-tag">TensorFlow</span>
            <span class="demo-tag">OpenCV</span>
            <span class="demo-tag">96.3%</span>
          </div>
        </div>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/2.gif" alt="Real-world validation" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo1_gif2_title">Real-world Validation</h4>
            <span class="citation-pill">30 FPS</span>
          </div>
          <p data-i18n="demo1_gif2_desc">Validation under real lighting conditions. Robust detection at 30 FPS with varying illumination and head movements.</p>
          <div class="demo-tags">
            <span class="demo-tag">Real-time</span>
            <span class="demo-tag">Robust</span>
            <span class="demo-tag">30 FPS</span>
          </div>
        </div>
      </div>
      
      <div class="paper-divider">
        <h3>Embedded System on NVIDIA Jetson Nano ¬∑ <span>27 citations</span></h3>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/3.gif" alt="Visual drowsiness detection on Jetson Nano" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo2_gif1_title">Visual Drowsiness Detection</h4>
            <span class="citation-pill"><15ms</span>
          </div>
          <p data-i18n="demo2_gif1_desc">Real-time eye analysis on NVIDIA Jetson Nano. Micro-sleep detection with visual alerts at <15ms latency.</p>
          <div class="demo-tags">
            <span class="demo-tag">Jetson Nano</span>
            <span class="demo-tag">TensorRT</span>
            <span class="demo-tag"><15ms</span>
          </div>
        </div>
      </div>
      
      <div class="demo-card">
        <div class="demo-gif-container">
          <img src="assets/gifs/4.gif" alt="Yawn detection using MAR" loading="lazy">
        </div>
        <div class="demo-content">
          <div class="demo-header">
            <h4 data-i18n="demo2_gif2_title">Yawn Detection (MAR)</h4>
            <span class="citation-pill">MAR</span>
          </div>
          <p data-i18n="demo2_gif2_desc">Mouth Aspect Ratio (MAR) analysis for real-time fatigue detection. Integrated with facial landmark tracking.</p>
          <div class="demo-tags">
            <span class="demo-tag">MAR</span>
            <span class="demo-tag">Facial Landmarks</span>
            <span class="demo-tag">Multi-modal</span>
          </div>
        </div>
      </div>
      
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ PUBLICATIONS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="publications">
  <div class="section-inner">
    <div class="section-label" data-i18n="pubs_label">Publications</div>
    <div class="section-title" data-i18n="pubs_title">Selected Publications</div>

    <div class="pub-filters">
      <button class="pub-filter active" data-filter="all" onclick="filterPubs('all')" data-i18n="filter_all">All</button>
      <button class="pub-filter" data-filter="cogni" onclick="filterPubs('cogni')" data-i18n="filter_cogni">Cognitive Monitoring</button>
      <button class="pub-filter" data-filter="cv" onclick="filterPubs('cv')" data-i18n="filter_cv">Computer Vision</button>
    </div>

    <div class="pub-list" id="pub-list">
      <div class="pub-card" data-category="cogni">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3390/app13137849" target="_blank">A CNN-based approach for driver drowsiness detection by real-time eye state identification</a></div>
          <div class="pub-meta">R. Florez, F. Palomino-Quispe, RJ Coaquira-Castillo et al. ¬∑ <em>Applied Sciences</em> 13 (13), 7849 ¬∑ 2023</div>
        </div>
        <div class="citation-badge">82 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cogni">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3390/s24196261" target="_blank">A real-time embedded system for driver drowsiness detection based on visual analysis of the eyes and mouth using CNN and mouth aspect ratio</a></div>
          <div class="pub-meta">R. Florez, F. Palomino-Quispe, AB Alvarez et al. ¬∑ <em>Sensors</em> 24 (19), 6261 ¬∑ 2024</div>
        </div>
        <div class="citation-badge">27 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cv">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3390/app15095040" target="_blank">Coffee-leaf diseases and pests detection based on YOLO models</a></div>
          <div class="pub-meta">J. Fragoso, C. Silva, T. Paixao, AB Alvarez, R. Florez et al. ¬∑ <em>Applied Sciences</em> 15 (9), 5040 ¬∑ 2025</div>
        </div>
        <div class="citation-badge">14 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cv">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.3991/ijoe.v21i07.54439" target="_blank">Illumination-Robust Conjunctival Image Preprocessing for Accurate Segmentation and Anemia Detection Using Deep Learning</a></div>
          <div class="pub-meta">JH Fuentes Being√≥lea, F. Palomino-Quispe, JC Herrera-Levano, R. Florez et al. ¬∑ <em>iJOE</em> 21 (7) ¬∑ 2025</div>
        </div>
        <div class="citation-badge">1 <span data-i18n="cit">citations</span></div>
      </div>

      <div class="pub-card" data-category="cv">
        <div>
          <div class="pub-title"><a href="https://doi.org/10.1109/INTERCON52678.2021.9532881" target="_blank">Low-cost mini humanoid robot mechanical design for mini humanoid robot contest Intercon 2021</a></div>
          <div class="pub-meta">R. Vilavita, F. Justo, R. Florez, N. Figueroa ¬∑ <em>IEEE XXVIII Intercon</em> ¬∑ 2021</div>
        </div>
        <div class="citation-badge">5 <span data-i18n="cit">citations</span></div>
      </div>
    </div>
    
    <p class="pub-footer">
      <span data-i18n="pubs_full_list">Full list on</span>
      <a href="https://scholar.google.com/citations?user=Xf8JgfsAAAAJ&hl" target="_blank">Google Scholar</a> ¬∑
      <a href="https://www.researchgate.net/profile/Ruben-Florez-Zela" target="_blank">ResearchGate</a>
    </p>
  </div>
</section>

<!-- ‚îÄ‚îÄ TEACHING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="teaching">
  <div class="section-inner">
    <div class="section-label" data-i18n="teaching_label">Teaching</div>
    <div class="section-title" data-i18n="teaching_title">Teaching Experience</div>
    <p class="teaching-sub" data-i18n="teaching_sub">Universidad Nacional de San Antonio Abad del Cusco (UNSAAC) ¬∑ School of Electronic Engineering ¬∑ April 2024 ‚Äì Present</p>
    <div class="teaching-grid">
      <div class="course-card">
        <h4 data-i18n="course1">Artificial Intelligence</h4>
        <p data-i18n="course_level">Undergraduate ¬∑ Electronic Engineering</p>
      </div>
      <div class="course-card">
        <h4 data-i18n="course2">Digital Image Processing</h4>
        <p data-i18n="course_level">Undergraduate ¬∑ Electronic Engineering</p>
      </div>
      <div class="course-card">
        <h4 data-i18n="course3">Robotics</h4>
        <p data-i18n="course_level">Undergraduate ¬∑ Electronic Engineering</p>
      </div>
      <div class="course-card">
        <h4 data-i18n="course4">Electronics Laboratory</h4>
        <p data-i18n="course_level">Undergraduate ¬∑ Electronic Engineering</p>
      </div>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ SELECTED ACHIEVEMENTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="achievements">
  <div class="section-inner">
    <div class="section-label" data-i18n="ach_label">Achievements</div>
    <div class="section-title" data-i18n="ach_title">Selected Achievements</div>
    <div class="ach-grid">
      <div class="ach-card ach-blue">
        <div class="ach-num">143+</div>
        <div class="ach-desc" data-i18n="ach1">Total citations ‚Äî one paper surpassing 82 citations within 2 years</div>
      </div>
      <div class="ach-card ach-teal">
        <div class="ach-num">#1</div>
        <div class="ach-desc" data-i18n="ach2">Most cited paper on real-time CNN-based eye-state drowsiness detection ‚Äî 82 citations</div>
      </div>
      <div class="ach-card ach-navy">
        <div class="ach-num">V</div>
        <div class="ach-desc" data-i18n="ach3">RENACYT Level V researcher ‚Äî CONCYTEC national recognition</div>
      </div>
      <div class="ach-card ach-blue">
        <div class="ach-num">7+</div>
        <div class="ach-desc" data-i18n="ach4">Active peer reviewer for international journals including ACM TIST and Scientific Reports</div>
      </div>
      <div class="ach-card ach-teal">
        <div class="ach-num">üèÜ√ó3</div>
        <div class="ach-desc" data-i18n="ach5">First place in regional/national competitions including First Andean Hackathon (6 countries)</div>
      </div>
      <div class="ach-card ach-navy">
        <div class="ach-num">Q1</div>
        <div class="ach-desc" data-i18n="ach6">Target submission 2026 ‚Äî multimodal neuro-ocular system to high-impact journal</div>
      </div>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ PEER REVIEW ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section>
  <div class="section-inner">
    <div class="section-label" data-i18n="review_label">Peer Review</div>
    <div class="section-title" data-i18n="review_title">Peer Review Activity</div>
    <table class="review-table">
      <thead>
        <tr>
          <th data-i18n="review_th1">Journal</th>
          <th data-i18n="review_th2">Publisher</th>
          <th data-i18n="review_th3">Reviews</th>
        </tr>
      </thead>
      <tbody>
        <tr><td class="journal-highlight">Scientific Reports</td><td>Nature Portfolio</td><td><span class="review-count">2</span></td></tr>
        <tr><td class="journal-highlight">ACM Trans. on Intelligent Systems and Technology</td><td>ACM</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Journal of Ambient Intelligence and Humanized Computing</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Discover Applied Sciences</td><td>Springer</td><td><span class="review-count">3</span></td></tr>
        <tr><td>Discover Artificial Intelligence</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Discover Electronics</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>Discover Internet of Things</td><td>Springer</td><td><span class="review-count">1</span></td></tr>
        <tr><td>IAES Int'l Journal of Artificial Intelligence</td><td>IAES</td><td><span class="review-count">2</span></td></tr>
        <tr><td>Indian Journal of Science and Technology</td><td>IJST</td><td><span class="review-count">1</span></td></tr>
      </tbody>
    </table>
    <p class="review-orcid">
      <span data-i18n="review_orcid_note">Verified via ORCID iD:</span>
      <a href="https://orcid.org/0000-0002-9833-0213" target="_blank">0000-0002-9833-0213</a>
    </p>
  </div>
</section>

<!-- ‚îÄ‚îÄ CONTACT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<section id="contact" class="contact-section">
  <div class="section-inner">
    <div class="section-label" data-i18n="contact_label">Contact</div>
    <div class="section-title" data-i18n="contact_title">Get in Touch</div>
    <div class="contact-grid">
      <div>
        <p class="contact-text" data-i18n="contact_text">I am open to research collaborations, dataset sharing, joint publications, academic exchanges, and PhD opportunities in neuroengineering, human factors AI, or safety-critical systems.</p>
        <div class="contact-items">
          <a href="mailto:rubendfz2206@gmail.com" class="contact-item">
            <span class="contact-icon">‚úâ</span>rubendfz2206@gmail.com
          </a>
          <a href="https://www.linkedin.com/in/rubenflorez/" class="contact-item" target="_blank">
            <span class="contact-icon">in</span>linkedin.com/in/rubenflorez
          </a>
          <a href="https://orcid.org/0000-0002-9833-0213" class="contact-item" target="_blank">
            <span class="contact-icon">ID</span>ORCID 0000-0002-9833-0213
          </a>
          <a href="https://scholar.google.com/citations?user=Xf8JgfsAAAAJ&hl" class="contact-item" target="_blank">
            <span class="contact-icon">GS</span>Google Scholar
          </a>
          <a href="https://www.researchgate.net/profile/Ruben-Florez-Zela" class="contact-item" target="_blank">
            <span class="contact-icon">RG</span>ResearchGate
          </a>
        </div>
      </div>
      <div class="open-to">
        <h4 data-i18n="open_title">Open to</h4>
        <ul>
          <li data-i18n="open1">Research collaborations</li>
          <li data-i18n="open2">Dataset sharing</li>
          <li data-i18n="open3">Joint publications</li>
          <li data-i18n="open4">Academic exchanges</li>
          <li data-i18n="open5">PhD opportunities</li>
          <li data-i18n="open6">Industry partnerships</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<!-- ‚îÄ‚îÄ FOOTER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<footer>
  <span data-i18n="footer">¬© 2025 Ruben Dario Florez-Zela ¬∑ UNSAAC ¬∑ Cusco, Peru</span>
</footer>

<!-- ‚îÄ‚îÄ SCRIPTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ -->
<script src="data/translations.json"></script>
<script>
function filterPubs(category) {
  document.querySelectorAll('.pub-card').forEach(card => {
    if (category === 'all') {
      card.classList.remove('hidden');
    } else {
      if (card.dataset.category === category) {
        card.classList.remove('hidden');
      } else {
        card.classList.add('hidden');
      }
    }
  });
  
  document.querySelectorAll('.pub-filter').forEach(btn => {
    if (btn.dataset.filter === category) {
      btn.classList.add('active');
    } else {
      btn.classList.remove('active');
    }
  });
}

let currentLang = 'en';

function setLang(lang) {
  currentLang = lang;
  const t = translations[lang];

  document.querySelectorAll('[data-i18n]').forEach(el => {
    const key = el.dataset.i18n;
    if (t[key] !== undefined) el.innerHTML = t[key];
  });

  document.querySelectorAll('.lang-btn').forEach(btn => {
    btn.classList.toggle('active', btn.dataset.lang === lang);
  });

  const cvFile = lang === 'es' ? 'CV_Florez_ES.pdf' : 'CV_Florez_EN.pdf';
  document.getElementById('cv-nav-btn').href = cvFile;
  document.getElementById('cv-hero-btn').href = cvFile;

  document.documentElement.lang = lang;
}

document.addEventListener('DOMContentLoaded', function() {
  setLang('en');
});
</script>

</body>
</html>
